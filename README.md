# ğŸ¤– Market Research Crew API

A multi-agent AI system built with **CrewAI** and **FastAPI** that performs comprehensive market research on any topic. The system uses a team of specialized AI agents working together to research, analyze, write, and edit professional market research reports.

---

## ğŸ¯ What This Does

This project creates an **AI Agent Crew** that:
1. **Senior Research Agent** - Searches the web and gathers information on your topic
2. **Market Analyst Agent** - Analyzes the research data and identifies trends
3. **Content Writer Agent** - Writes a comprehensive report from the analysis
4. **Senior Editor Agent** - Reviews and polishes the final report

All agents work sequentially in a pipeline to produce high-quality market research reports.

---

## ğŸ“ Project Structure

```
crew/
â”œâ”€â”€ config.py              # Environment settings (API keys)
â”œâ”€â”€ docker-compose.yml     # Docker compose configuration
â”œâ”€â”€ Dockerfile             # Docker build instructions
â”œâ”€â”€ pyproject.toml         # Python dependencies
â”œâ”€â”€ uv.lock                # Locked dependencies
â”œâ”€â”€ .env                   # Environment variables (create this)
â”œâ”€â”€ README.md              # This file
â””â”€â”€ app/
    â”œâ”€â”€ main.py            # FastAPI application & endpoints
    â”œâ”€â”€ agents.py          # AI Agent definitions
    â”œâ”€â”€ tasks.py           # Task definitions for agents
    â”œâ”€â”€ crew_runner.py     # Crew orchestration logic
    â”œâ”€â”€ prompts.py         # Agent prompts (role, goal, backstory)
    â”œâ”€â”€ schemas.py         # Pydantic request/response models
    â””â”€â”€ tools.py           # Agent tools (web search, etc.)
```

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose installed
- API Keys:
  - **Groq API Key** (for LLM) - Get from [groq.com](https://groq.com)
  - **Serper API Key** (for web search) - Get from [serper.dev](https://serper.dev)

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd crew
```

### 2. Create Environment File
Create a `.env` file in the root directory:

```env
LLM_API_KEY=your_groq_api_key_here
LLM_API_BASE=https://api.groq.com/openai/v1
MODEL_NAME=llama-3.1-70b-versatile
SERPER_API_KEY=your_serper_api_key_here
```

### 3. Run with Docker
```bash
docker-compose up --build
```

### 4. Access the API
- **API Base URL:** `http://localhost:8000`
- **Health Check:** `http://localhost:8000/health`
- **API Docs:** `http://localhost:8000/docs`

---

## ğŸ“¡ API Endpoints

### Health Check
```http
GET /health
```
**Response:**
```json
{
  "status": "healthy"
}
```

### Generate Research Report
```http
POST /research
Content-Type: application/json

{
  "topic": "AI Agents in 2025"
}
```

**Response:**
```json
{
  "status": "success",
  "result": "... comprehensive market research report ..."
}
```

## âš™ï¸ Configuration

| Environment Variable | Description | Example |
|---------------------|-------------|---------|
| `LLM_API_KEY` | Your Groq API key | `gsk_xxxx...` |
| `LLM_API_BASE` | LLM API base URL | `https://api.groq.com/openai/v1` |
| `MODEL_NAME` | Model to use | `llama-3.1-70b-versatile` |
| `SERPER_API_KEY` | Serper.dev API key for web search | `xxxx...` |

---

## ğŸ› ï¸ Local Development (Without Docker)

### Using UV (Recommended)
```bash
# Install dependencies
uv sync

# Run the server
uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Using pip
```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Install dependencies
pip install -e .

# Run the server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

---

## ğŸ³ Docker Commands

```bash
# Build and run
docker-compose up --build

# Run in background
docker-compose up -d

# Stop containers
docker-compose down

# View logs
docker-compose logs -f
```

---

## ğŸ§  How the Agent Crew Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Request   â”‚
â”‚  (Topic Input)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Senior Research â”‚ â”€â”€â–º Searches web, gathers data
â”‚     Agent       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Market Analyst  â”‚ â”€â”€â–º Analyzes trends & insights
â”‚     Agent       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Content Writer  â”‚ â”€â”€â–º Writes comprehensive report
â”‚     Agent       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Senior Editor   â”‚ â”€â”€â–º Reviews & polishes content
â”‚     Agent       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final Report   â”‚
â”‚    (Output)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Tech Stack

- **[CrewAI](https://github.com/joaomdmoura/crewAI)** - Multi-agent orchestration framework
- **[FastAPI](https://fastapi.tiangolo.com/)** - Modern Python web framework
- **[Groq](https://groq.com/)** - Fast LLM inference
- **[Serper](https://serper.dev/)** - Google Search API
- **[Pydantic](https://docs.pydantic.dev/)** - Data validation
- **[UV](https://github.com/astral-sh/uv)** - Fast Python package manager
- **[Docker](https://www.docker.com/)** - Containerization

---

## ğŸ“„ License

MIT License

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

